# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from typing import Dict, List

import pyarrow as pa
import ray
from ray.types import ObjectRef

@ray.remote
class RayDPBlockStore:
    """Per-executor block owner for Spark->Ray Dataset conversion.

    The JVM side can invoke the actor method `put_arrow_ipc` via Ray's cross-language
    actor call support so that this Python actor becomes the owner of the created
    objects, without using Ray's experimental `ray.put(_owner=...)` API.
    """

    def _get_raydp_blocks_by_key(self) -> Dict[str, ObjectRef]:
        blocks = getattr(self, "_raydp_blocks_by_key", None)
        if blocks is None:
            blocks = {}
            setattr(self, "_raydp_blocks_by_key", blocks)
        return blocks

    def put_arrow_ipc(self, batch_key: str, ipc_bytes: bytes) -> bool:
        """Create one Ray Dataset block owned by this actor.

        Args:
            batch_key: A per-batch application-level key generated by the JVM.
            ipc_bytes: Arrow IPC stream bytes written by ArrowStreamWriter on Spark executors.

        Returns:
            True when the block has been created and stored.
        """
        reader = pa.ipc.open_stream(pa.BufferReader(ipc_bytes))
        table = reader.read_all()
        ref = ray.put(table)
        self._get_raydp_blocks_by_key()[batch_key] = ref
        return True


    def get_block_refs(self, batch_keys: List[str]):
        """Fetch (and remove) stored block refs for the given keys."""
        blocks = self._get_raydp_blocks_by_key()
        refs = []
        for k in batch_keys:
            refs.append(blocks.pop(k))
        return refs


class RayDPBlockStoreActorRegistry:
    def get_or_create_blockstore_actor(
            self,
            actor_name: str,
            node_address: str,
            num_cpus: float,
            memory: float,
            node_affinity: float) -> bool:
        blockstore_actors = getattr(self, "_blockstore_actors", None)
        if blockstore_actors is None:
            blockstore_actors = {}
            setattr(self, "_blockstore_actors", blockstore_actors)

        if actor_name in blockstore_actors:
            return False

        # Clamp to a sane range; Ray nodes have 1.0 of the special node:<ip> resource.
        if node_affinity is None or node_affinity <= 0:
            node_affinity = 0.001
        node_affinity = min(1.0, float(node_affinity))

        opts = {
            "name": actor_name,
            "resources": {f"node:{node_address}": node_affinity},
            "num_cpus": max(0, num_cpus),
            "memory": max(0, memory),
        }
        actor = RayDPBlockStore.options(**opts).remote()
        blockstore_actors[actor_name] = actor
        return True
